\documentclass{article}

% use numbers for citations to save space
\PassOptionsToPackage{numbers, compress}{natbib}

% either empty (for submission), 'preprint', or 'final'
\def\status{}
\usepackage[\status]{neurips_2024}

\input{preamble/custom_early.tex}
\input{preamble/neurips_2024.tex}
% follow DL notation from the Goodfellow book
\input{preamble/goodfellow.tex}
\input{preamble/custom.tex}
\input{preamble/metadata.tex}

\definecolor{darkgreen}{rgb}{0,0.6,0}
%\newcommand{\AK}[2][]{\alternatingtodo[color=red!40, #1]{#2 }}
\newcommand{\temp}[1]{\textcolor{blue}{#1}}
\newcommand{\AW}[1]{\textcolor{darkgreen}{#1}}
\newcommand{\mycolor}{blue}

\begin{document}

\maketitle

\begin{abstract}
  For the accelerated evaluation differential operators, we explore automated computational graph simplifications based on the concept of linearity.
  These simplification can be used for many common differential operators like the Laplacian that computes the sum of diagonal elements of the Hessian using Taylor mode automatic differentiation (\texttt{jet}s).
  We show that the required Taylor coefficients can first be summed, then propagated, which reduces the overall computational cost.
  Due to the simplicity of this simplification (propagating a sum up a computational graph), we argue that it could (or should) be performed by the just-in-time (\texttt{jit}) compiler in machine learning frameworks.
  Our preliminary experiments achieve promising, fully automated, speed-ups, which we believe can easily be integrated into automatic differentiation libraries.
\end{abstract}

\AW{comments
 \begin{itemize}
     \item compute graph, computation graph $\Rightarrow$ computational graph?
     \item Taylor-mode AD or Taylor-mode of AD?
 \end{itemize}
}\section{Introduction}\label{sec:introduction}
\input{sections/introduction.tex}

\section{Background on AD for Higher-Order Derivatives}\label{sec:background}
\input{sections/background.tex}

\section{The Collapsed Taylor-Mode}\label{sec:methodology}
\input{sections/method}

% \section{Kronecker-Factored Approximate Curvature for
% PINNs}\label{sec:kfac_pinns}
% \input{sections/contribution.tex}

\section{Implementation \& Experiments}\label{sec:experiments}
\input{sections/experiments.tex}

% \section{Discussion and Conclusion}\label{sec:conclusion}
% \input{sections/conclusion.tex}
% \input{sections/acknowledgements.tex}

\bibliography{references}
\bibliographystyle{icml2024.bst}

\clearpage
\appendix

% Label appendix equations as (A1), (B10) etc.
\renewcommand\theequation{\thesection\arabic{equation}}
\renewcommand\thefigure{\thesection\arabic{figure}}
\renewcommand\thetable{\thesection\arabic{table}}

\section{Visual Tour: From Function to Collapsed Taylor Mode}\label{sec:appendix-visual-tour}
\input{figures/interface_overview}
\clearpage

\section{Linearity for Taylor-mode AD}
\input{sections/appendix_linearity_for_taylor}

\section{Fa\`a Di Bruno Formula Cheat Sheet}\label{sec:faa-di-bruno-cheatsheet}
\input{sections/faa_di_bruno}



\section{TTC}\label{sec:appendix_ttc}
\input{sections/appendix_ttc}

\section{JAX benchmark}
\label{sec:jax-benchmark}
\input{sections/appendix_jax}

% \input{sections/appendix.tex}
% \input{sections/checklist.tex}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
