\paragraph{Design decisions and limitations.} Although JAX already offers an experimental Taylor mode implementation, we re-implemented Taylor mode in PyTorch, taking heavy inspiration from the JAX implementation for the interface.
We decided so because PyTorch's \texttt{fx} library provides a user-friendly official interface to capture and transform compute graphs of functions to apply our proposed collapsing.
While we believe that such graph transformations should in principle be feasible in JAX as well (and could \eg be integrated into its \texttt{jit} compiler), it seems that this can currently only be achieved with (potentially fragile) internal APIs and requires a deep understanding of its internal tracing mechanisms.
Main advantage seems to be that we can clearly disentangle building the graph from simplifying it using linearity, whereas in JAX we could write a custom interpreter that would have to re-implement the logic of summing the $K$-th component for abitrary $K$.

\paragraph{Usage.} Our implementation takes a PyTorch function (\eg a neural net) and first captures its compute graph using \texttt{torch.fx}'s symbolic tracing mechanism, then replaces each operation with its Taylor arithmetic.
This yields the compute graph of the function's $K$-jet.
Users can use this vanilla Taylor mode to define their differential operator's computation. 
The collapsing is done by again tracing said computation with \texttt{torch.fx} and rewriting the resulting graph, propagating the summation of highest coefficient up.
The resulting graph performs the same computation, but uses our collapsed Taylor mode.
See \Cref{fig:interface-overview} for a visual walk-through of the procedure.

TODO Limitations.

\paragraph{Experimental procedure.} We compare our collapsed Taylor mode with vanilla Taylor mode and nested first-order AD on the previously discussed differential operators in PyTorch on an NVIDIA RTX 6000 with .




\begin{figure*}[!t]
  \centering
  % From https://tex.stackexchange.com/a/7318
  \newcolumntype{C}{ >{\centering\arraybackslash} m{0.12\textwidth} }
  \newcolumntype{D}{ >{\centering\arraybackslash} m{0.27\textwidth} }
  \begin{tabular}{CDDD}
    & \textbf{Laplacian $(D=50)$}
    & \textbf{Weighted Laplacian $(D=50)$}
    & \textbf{Bi-harmonic $(D=5)$}
    \\
    \textbf{Exact}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_laplacian_vary_batch_size.pdf}
    &  \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_weighted_laplacian_vary_batch_size.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_5_name_bilaplacian_vary_batch_size.pdf}
    \\
    \textbf{Stochastic}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_laplacian_vary_num_samples.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_weighted_laplacian_vary_num_samples.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_256_device_cuda_dim_5_distribution_normal_name_bilaplacian_vary_num_samples.pdf}
  \end{tabular}

  \newsavebox{\benchmarkLegend}
  \savebox{\benchmarkLegend}{
    \begin{tikzpicture}[font=\small]
      \matrix [%
      matrix of nodes,%
      ampersand replacement=\&,% to use inside a savebox
      nodes={anchor=west, align=left, inner sep=1pt},%
      column sep=1ex,%
      row sep=0ex,%
      ] (legend)
      {
        \& \draw[tab-blue] plot[mark=*] coordinates {(0,0)};
        \& Nested first-order AD\phantom{y}\quad
        \& \draw[tab-orange] plot[mark=triangle*, rotate=270] coordinates {(0,0)};
        \& Standard Taylor mode\quad
        \& \draw[tab-green] plot[mark=triangle*, rotate=90] coordinates {(0,0)};
        \& Collapsed Taylor mode (ours)
        \\
        \& \node[anchor=center]{\tikz\draw[thick] (0, 0) to ++(2.5ex, 0);};
        \& Differentiable
        \& \node[anchor=center, opacity=0.5]{\tikz\draw[thick, dashed] (0, 0) to ++(2.5ex, 0);};
        \& Non-differentiable
        \& \node[anchor=center, opacity=0.0]{\tikz\draw[thick] (0, 0) to ++(2.5ex, 0);};
        \\
      };

      \draw[gray, rounded corners] (current bounding box.north west) rectangle (current bounding box.south east);
    \end{tikzpicture}
  }
  \begin{tikzpicture}
    \node {\usebox{\benchmarkLegend}};
  \end{tikzpicture}

  \caption{\textbf{\textcolor{tab-green}{Collapsed Taylor mode} is faster than \textcolor{tab-orange}{standard Taylor mode} and \textcolor{tab-blue}{nested first-order automatic differentiaion} while using less or the same memory, \textcolor{black!50!white}{opaque} memory consumptions are for non-differentiable computations.}
    Results are on GPU and we use a $D \to 768 \to 768 \to 512 \to 512 \to 1$ MLP with tanh activations with $D=50$ for the Laplacians and $D=5$ for the Bi-harmonic operator.
    The exact computation varies the batch size, and the approximate computation fixes $N=2048$ for the Laplacians, and $N=256$ for the Bi-Laplacian, and varies the number of Monte-Carlo samples such that $S < D$ for the Laplacians, and $2 + 3S < 6D^2 - 3D + 6$ for the Bi-Laplacian (we can compute exactly otherwise).
    For each approach, we fit a line to the data and report the slope in \Cref{tab:benchmark}  to quantify the relative speedup and memory reduction.
  }
  \label{fig:benchmark}
\end{figure*}

\begin{table}[!t]
  \centering
  \caption{\textbf{Benchmark from \Cref{fig:benchmark} in numbers.}
    We fit linear functions and report their slopes, \ie how much run time and memory increase when incrementing the batch size or number of Monte-Carlo samples.
    Our collapsed Taylor mode is up to two times faster than nested first-order autodiff, while using 80\% of memory in the differentiable, and 70\% in the non-differentiable, setting.
    All numbers are shown with two significant digits and bold values are best according to parenthesized values.}
  \label{tab:benchmark}
  \vspace{1.5ex}
  % paths where the performances are stored
  \def\datapathLaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_laplacian_vary_batch_size}
  \def\datapathLaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_laplacian_vary_num_samples}
  \def\datapathWeightedLaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_weighted_laplacian_vary_batch_size}
  \def\datapathWeightedLaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_weighted_laplacian_vary_num_samples}
  \def\datapathBilaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_5_name_bilaplacian_vary_batch_size}
  \def\datapathBilaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_256_device_cuda_dim_5_distribution_normal_name_bilaplacian_vary_num_samples}
  \resizebox{\linewidth}{!}{%
    % configuration options for the \num command
    \sisetup{%
      % scientific-notation=true,%
      round-mode=figures,%
      round-precision=2,%
      detect-weight, % for bolding to work
      tight-spacing=true, % less space around \cdot
    }
    \begin{tabular}{ccc|cccc}
      \toprule
      \textbf{Mode}
      & \makecell{\textbf{Per-datum or } \\ \textbf{-sample cost}}
      & \textbf{Implementation}
      & \textbf{Laplacian}
      & \makecell{\textbf{Weighted} \\ \textbf{Laplacian}}
      & \textbf{Bi-harmonic}
      \\
      \midrule
      \multirow{9}{*}{\textbf{Exact}}
      & \multirow{3}{*}{Time [ms]}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_best.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_best.txt}
      & \input{\datapathBilaplacianExact/hessian_trace_best.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianExact/jet_naive_best.txt}
      & \input{\datapathWeightedLaplacianExact/jet_naive_best.txt}
      & \input{\datapathBilaplacianExact/jet_naive_best.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_best.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_best.txt}}
      & \textbf{\input{\datapathBilaplacianExact/jet_simplified_best.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB] \\ (differentiable)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_peakmem.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_peakmem.txt}
      & \textbf{\input{\datapathBilaplacianExact/hessian_trace_peakmem.txt}}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianExact/jet_naive_peakmem.txt}
      & \input{\datapathWeightedLaplacianExact/jet_naive_peakmem.txt}
      & \input{\datapathBilaplacianExact/jet_naive_peakmem.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_peakmem.txt}}
      & \input{\datapathBilaplacianExact/jet_simplified_peakmem.txt}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB] \\ (non-diff.)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathBilaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \textbf{\input{\datapathLaplacianExact/jet_naive_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_naive_peakmem_nondifferentiable.txt}}
      & \input{\datapathBilaplacianExact/jet_naive_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathBilaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      \\
      \midrule
      \multirow{9}{*}{\textbf{Stochastic}}
      & \multirow{3}{*}{Time [ms]}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_best.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_best.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_best.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianStochastic/jet_naive_best.txt}
      & \input{\datapathWeightedLaplacianStochastic/jet_naive_best.txt}
      & \input{\datapathBilaplacianStochastic/jet_naive_best.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_best.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_best.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_best.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB]\\(differentiable)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_peakmem.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_peakmem.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_peakmem.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianStochastic/jet_naive_peakmem.txt}
      & \input{\datapathWeightedLaplacianStochastic/jet_naive_peakmem.txt}
      & \input{\datapathBilaplacianStochastic/jet_naive_peakmem.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_peakmem.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB]\\(non-diff.)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \textbf{\input{\datapathLaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}}
      & \input{\datapathBilaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      \\
      \bottomrule
    \end{tabular}
  }
\end{table}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
