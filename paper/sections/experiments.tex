\todo{the example below could be used as benchmark? Otherwise we can remove it.}

\paragraph{Example for weighted sum of second-order derivatives.}
Let's consider the Fokker-Planck equation for the evolution of a probability density $p(\vx, t)$ with $\vx \in \sR^D$ and $t \in \sR_{\le 0}$ given by
\begin{align}
  \frac{\partial p(\vx, t)}{\partial t}
  =
  - \sum_{d=1}^D
  \frac{\partial}{\partial [\vx]_d} \left( [\vmu(\vx, t)]_d p(\vx, t) \right)
  +
  \sum_{i,j=1}^D
  \frac{\partial^2}{\partial [\vx]_i \partial [\vx]_j}
  \left[ \mD_{i,j}(\vx, t) p(\vx, t) \right]
\end{align}\todo{M: In the other examples we always considered the diffusivity term to be outside the derivative -- so no product rule is needed. Another thought. It might make more sense to put the Fokker-Planck equation to where we introduce the sum of weighted second derivatives, and here only consider the PDE operator.}
with positive definite diffusion tensor $\mD(\vx, t) = \nicefrac{1}{2} \mS(\vx, t) \mS(\vx, t)^{\top}$ where $\mS(\vx, t) \in \sR^{D \times M}$ with some $M \le D$.
After application of the product rule, we find that this term requires computing weighted sum of second-order derivative $\sum_{i,j} \mD_{i,j}  \nicefrac{\partial^2 p(\vx, t)}{\partial [\vx]_i \partial [\vx]_j}$.
By denoting $\vs_m$ the $m$-th column of $\mS$, we find that this expression can be expressed as $\sum_{m=1}^M \partial^2 p[\nicefrac{\vs_m}{\sqrt{2}}, \nicefrac{\vs_m}{\sqrt{2}}]$ and hence we can use compute this quantity with a second-order jet whose quadratic coefficients can be collapsed into a single one.

\todo{is this needed?}

\paragraph{Partially collapsed Taylor mode.}
A use case for such partially collapsed jets is in \cite{hu2023hutchinson}, which uses randomized Taylor mode (see \cref{subsec:randomized-taylor-mode}) to estimate the Laplacian.
In their application, the randomized Laplacian feeds into square loss.
While the Laplacian estimator itself is unbiased, squaring it in the loss function introduces a bias. 
Obtaining an unbiased estimator of the loss requires computing two randomized Laplacians using different sets of random vectors. 
We could handle this partial collapse and its propagation up the computation graph with our graph simplifications.
However, \cite{hu2023hutchinson} do not use this unbiased version in practice. 
They argue it has too much variance.


\begin{figure*}[!t]
  \centering
  % From https://tex.stackexchange.com/a/7318
  \newcolumntype{C}{ >{\centering\arraybackslash} m{0.12\textwidth} }
  \newcolumntype{D}{ >{\centering\arraybackslash} m{0.27\textwidth} }
  \begin{tabular}{CDDD}
    & \textbf{Laplacian $(D=50)$}
    & \textbf{Weighted Laplacian $(D=50)$}
    & \textbf{Bi-harmonic $(D=5)$}
    \\
    \textbf{Exact}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_laplacian_vary_batch_size.pdf}
    &  \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_weighted_laplacian_vary_batch_size.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_5_name_bilaplacian_vary_batch_size.pdf}
    \\
    \textbf{Stochastic}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_laplacian_vary_num_samples.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_weighted_laplacian_vary_num_samples.pdf}
    & \includegraphics{../jet/exp/exp01_benchmark_laplacian/figures/architecture_tanh_mlp_768_768_512_512_1_batch_size_256_device_cuda_dim_5_distribution_normal_name_bilaplacian_vary_num_samples.pdf}
  \end{tabular}

  \caption{\textbf{\textcolor{tab-green}{Collapsed Taylor mode} is faster than \textcolor{tab-orange}{standard Taylor mode} and \textcolor{tab-blue}{nested first-order automatic differentiaion} while using less or the same memory, \textcolor{black!50!white}{opaque} memory consumptions are for non-differentiable computations.}
    Results are on GPU and we use a $D \to 768 \to 768 \to 512 \to 512 \to 1$ MLP with tanh activations with $D=50$ for the Laplacians and $D=5$ for the Bi-harmonic operator.
    The exact computation varies the batch size, and the approximate computation fixes $N=2048$ for the Laplacians, and $N=256$ for the Bi-Laplacian, and varies the number of Monte-Carlo samples such that $S < D$ for the Laplacians, and $2 + 3S < 6D^2 - 3D + 6$ for the Bi-Laplacian (we can compute exactly otherwise).
    For each approach, we fit a line to the data and report the slope in \Cref{tab:benchmark}  to quantify the relative speedup and memory reduction.
  }
  \label{fig:benchmark}
\end{figure*}

\begin{table}[!t]
  \centering
  \caption{\textbf{Benchmark from \Cref{fig:benchmark} in numbers.}
    We fit linear functions and report their slopes, \ie how much run time and memory increase when incrementing the batch size or number of Monte-Carlo samples.
    Our collapsed Taylor mode is up to two times faster than nested first-order autodiff, while using 80\% of memory in the differentiable, and 70\% in the non-differentiable, setting.
    All numbers are shown with two significant digits and bold values are best according to parenthesized values.}
  \label{tab:benchmark}
  \vspace{1.5ex}
  % paths where the performances are stored
  \def\datapathLaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_laplacian_vary_batch_size}
  \def\datapathLaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_laplacian_vary_num_samples}
  \def\datapathWeightedLaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_50_name_weighted_laplacian_vary_batch_size}
  \def\datapathWeightedLaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_2048_device_cuda_dim_50_distribution_normal_name_weighted_laplacian_vary_num_samples}
  \def\datapathBilaplacianExact{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_device_cuda_dim_5_name_bilaplacian_vary_batch_size}
  \def\datapathBilaplacianStochastic{../jet/exp/exp01_benchmark_laplacian/performance/architecture_tanh_mlp_768_768_512_512_1_batch_size_256_device_cuda_dim_5_distribution_normal_name_bilaplacian_vary_num_samples}
  \resizebox{\linewidth}{!}{%
    % configuration options for the \num command
    \sisetup{%
      % scientific-notation=true,%
      round-mode=figures,%
      round-precision=2,%
      detect-weight, % for bolding to work
      tight-spacing=true, % less space around \cdot
    }
    \begin{tabular}{ccc|cccc}
      \toprule
      \textbf{Mode}
      & \makecell{\textbf{Per-datum or } \\ \textbf{-sample cost}}
      & \textbf{Implementation}
      & \textbf{Laplacian}
      & \makecell{\textbf{Weighted} \\ \textbf{Laplacian}}
      & \textbf{Bi-harmonic}
      \\
      \midrule
      \multirow{9}{*}{\textbf{Exact}}
      & \multirow{3}{*}{Time [ms]}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_best.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_best.txt}
      & \input{\datapathBilaplacianExact/hessian_trace_best.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianExact/jet_naive_best.txt}
      & \input{\datapathWeightedLaplacianExact/jet_naive_best.txt}
      & \input{\datapathBilaplacianExact/jet_naive_best.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_best.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_best.txt}}
      & \textbf{\input{\datapathBilaplacianExact/jet_simplified_best.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB] \\ (differentiable)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_peakmem.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_peakmem.txt}
      & \textbf{\input{\datapathBilaplacianExact/hessian_trace_peakmem.txt}}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianExact/jet_naive_peakmem.txt}
      & \input{\datapathWeightedLaplacianExact/jet_naive_peakmem.txt}
      & \input{\datapathBilaplacianExact/jet_naive_peakmem.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_peakmem.txt}}
      & \input{\datapathBilaplacianExact/jet_simplified_peakmem.txt}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB] \\ (non-diff.)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathWeightedLaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathBilaplacianExact/hessian_trace_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \textbf{\input{\datapathLaplacianExact/jet_naive_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_naive_peakmem_nondifferentiable.txt}}
      & \input{\datapathBilaplacianExact/jet_naive_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathBilaplacianExact/jet_simplified_peakmem_nondifferentiable.txt}}
      \\
      \midrule
      \multirow{9}{*}{\textbf{Stochastic}}
      & \multirow{3}{*}{Time [ms]}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_best.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_best.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_best.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianStochastic/jet_naive_best.txt}
      & \input{\datapathWeightedLaplacianStochastic/jet_naive_best.txt}
      & \input{\datapathBilaplacianStochastic/jet_naive_best.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_best.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_best.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_best.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB]\\(differentiable)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_peakmem.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_peakmem.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_peakmem.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \input{\datapathLaplacianStochastic/jet_naive_peakmem.txt}
      & \input{\datapathWeightedLaplacianStochastic/jet_naive_peakmem.txt}
      & \input{\datapathBilaplacianStochastic/jet_naive_peakmem.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_peakmem.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_peakmem.txt}}
      \\ \cmidrule{2-6}
      & \multirow{3}{*}{\makecell{Mem.\,[MiB]\\(non-diff.)}}
      & \textcolor{tab-blue}{Nested first-order}
      & \input{\datapathLaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathWeightedLaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      & \input{\datapathBilaplacianStochastic/hessian_trace_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-orange}{Standard Taylor}
      & \textbf{\input{\datapathLaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}}
      & \input{\datapathBilaplacianStochastic/jet_naive_peakmem_nondifferentiable.txt}
      \\
      &
      & \textcolor{tab-green}{Collapsed (ours)}
      & \textbf{\input{\datapathLaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathWeightedLaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      & \textbf{\input{\datapathBilaplacianStochastic/jet_simplified_peakmem_nondifferentiable.txt}}
      \\
      \bottomrule
    \end{tabular}
  }
\end{table}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
