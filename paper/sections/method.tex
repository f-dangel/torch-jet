We propose to exploit the linearity in the $K$th coefficients when propagating a family of $K$-jets through a computational graph to compute a differential operator like the Laplacian.
Such families of $K$-jets were already considered for the forward Laplace \cite{li2023forward} and randomized Taylor mode ~\cite{shi2024stochastic, hu2023hutchinson}.
Then, we show that differential operators with a suitable structure can be computed via the propagation of an appropriately chosen family of jets using an algorithm of Griewank et al.
\cite{griewank_evaluating_1999}.
The result will also include the ideas of \cite{shi2024stochastic} for computing arbitrary differential operators.
However, our proposed algorithm only needs jets of the highest derivative degree occurring in the differential operator.

\subsection{Exploiting Linearity to Collapse Taylor Mode AD}
To derive our proposed method, the considerations start with a sum over $K$th-order directional derivatives of a function $\vf$ like the Laplacian.
In our notation, this sum can be represented as
\begin{align}\label{eq:sum-k-directional}
  \textstyle % Comment out this line if we have enough space
  \sum_{r=1}^R\left<
  \partial^{K} \vf(\vx_0),
  \otimes_{k=1}^K \vv_r
  \right>.
\end{align}
For the Laplacian, one has $K = 2$, $R$ equals the dimension of $\vx$, i.e., $R = D$, and the vectors are chosen as the unit vectors $\vv_r = \ve_r\in \R^D$.
Instead of nesting derivative calculations to compute the full $K$-th order derivative tensor to afterwards select only the required derivatives, $K$-jets can be utilized to (theoretically) efficiently calculate the required derivatives directly.
In case of \cref{eq:sum-k-directional}, one propagates $R$ $K$-jets through the computational graph using Taylor mode as illustrated in the appendix \cref{eq:sum-taylor-mode-naive}. To obtain the differential operator \cref{eq:sum-k-directional}, it is crucial to select appropriate input $K$-jets. To this end, we select the $r$th $K$-jet to $\vx_{0, r} = \vx_0$, $\vx_{1, r} = \vv_r$ and $\vx_{2, r} = \ldots = \vx_{K, r} = \vzero$.

Without further optimizations, then standard Taylor mode propagates $1 + KN$ vectors through every node of the computational graph, where the length of the vectors depend on the individual node.
Subsequently, one has to sum up the corresponding highest derivatives to obtain \cref{eq:sum-k-directional} as illustrated for our simple example in the appendix, see \cref{eq:sum-taylor-mode-naive}.
The approach we propose here is based on the observation that there is a special element in the set of integer partitions $\partitioning(K)$, namely the trivial partition $\tilde{\sigma}= \{K\}$ corresponding to the term $ \nu(\tilde{\sigma}) \left< \partial \vg(\vh_0), \vh_{K, n} \right>$ in \eqref{eq:faa-di-bruno} with $\nu(\tilde{\sigma}) = 1$, yielding
\begin{equation}\label{eq:faa-di-bruno-expanded}
  \textstyle % Comment out this line if we have enough space
  \vf_{K, n}
  =
  \vg_{K,n}
  =
  \sum_{
    \sigma \in \partitioning(K) \setminus \{\tilde{\sigma}\}
  }
  \nu(\sigma) \left<
    \partial^{|\sigma|} \vg(\vh_0),
    \tensorprod{s \in \sigma} \vh_{K, n}
  \right>
  +
  \left<
    \partial \vg(\vh_0),
    \vh_{K, n}
  \right>
\end{equation}
for our simple example.
The last inner-product term on the right-hand side is linear in $\vh_{K,n}$, marking the key property for our method.
To compute the sum of $\{\vg_{K, n}\}_n$, i.e., \cref{eq:sum-k-directional}, it is possible to directly propagate their sum, like $\sum_n \vh_{K,n}$, due to the linearity of $\left<\partial \vh, \bullet \right>$ and $\left< \partial \vg, \bullet \right>$ instead of passing the highest coefficients, like $\{\vh_{K,n}\}_n$, separately along the nodes of the computational graph.
This observation also holds for general functions $ \vf$.
Combining this insight with the Taylor mode yields our proposed {\em collapsed Taylor-mode AD}.
It propagates only $1 \!+\!
(K \!- \!1)N \!+\!
1$ vectors at every node in the computational graph, where the length of the vectors varies for each individual node in the same way as for the standard Taylor mode.
For our simple example, the collapsed Taylor-mode AD is detailed in the appendix, see \cref{eq:sum-taylor-mode-efficient}, where the changes are highlighted in \textcolor{\colorcTM}{\colorcTMname}.
To emphasize that the saving of $N-1$ coefficients at every node in the computational graph is indeed significant for common applications, important operators are discussed below.

\subsection{Second-order Operators}

\paragraph{Laplacian.} The Laplace operator (or simply \emph{Laplacian}) plays a central role in Physics and engineering, including electrostatics, fluid dynamics, heat conduction, and quantum mechanics \cite{foulkes2001quantum, pfau2020ab}.
It contains the Hessian trace of each element of a function, \ie, for $\vf: \sR^D \to \sR^C$, it is
\begin{subequations}
  \begin{align}\label{eq:laplacian}
    \textstyle % Comment out this line if we have enough space
    \underbrace{
    \Delta \vf(\vx_0)
    }_{\in \sR^C}
    :=
    \left<
    \partial^2 \vf(\vx_0), \mI_D
    \right>
    \quad
    \begin{cases}
      = \sum_{d=1}^D \left<
      \partial^2 \vf(\vx_0),
      \ve_d^{\otimes 2}
      \right>
      &\text{(exact)}
      \\
      \overset{\text{\cite{shi2024stochastic}}}{\approx}
      \frac{1}{S} \sum_{s=1}^S
      \left<
      \partial^2 \vf(\vx_0),
      \vv_s^{\otimes 2}
      \right>
      &\text{(stochastic)}
    \end{cases}
  \end{align}
  with the $d$-th standard basis vector $\ve_d$ used for exact computation, and $S$ random vectors $\vv_s$ drawn \iid from a distribution with unit variance (\eg Rademacher or standard Gaussian) for stochastic estimation.
  By pattern-matching \cref{eq:laplacian} with the RHS of \cref{eq:sum-k-directional} we conclude that $K=2$, and the following choices for computing the Laplacian with standard Taylor mode:
  \begin{align}
    \begin{array}{rlrlrlll}
      \{(\vx_{0,d} & = \vx_0, &\vx_{1, d} & = \ve_d, & \vx_{2,d} &= \vzero)\}_{d=1}^D
                                                                   \quad
      &{\color{tab-orange} 1 + D + D\, \text{vectors}}
        \quad
      &\text{(exact)}
      \\[1ex]
      \{(\vx_{0,s} & = \vx_0, &\vx_{1, s} & = \vv_s, &\vx_{2,s} & = \vzero)\}_{s=1}^S
                                                                  \quad
      &{\color{tab-orange} 1 + S + S\, \text{vectors}}
        \quad
      &\text{(stochastic)}
    \end{array}.
  \end{align}
\end{subequations}
Collapsing standard Taylor mode yields {\color{tab-green}$1 + D + 1$} (exact) and {\color{tab-green}{$1 + S + 1$}} (stochastic) vectors.
In fact, the collapsed Taylor mode for the exact Laplacian is the forward Laplacian from \citet{li2023forward} (see \cref{eq:laplacian-efficient} for detailed presentation of the forward propagation).
Note how we seamlessly can also support more efficient stochastic approximation.

\paragraph{Weighted Laplacian.}
A natural generalization of the Laplacian involves contracting with a positive semi-definite matrix $\mD = \msigma \msigma^\top \in \mathbb R^{D\times D}$ rather than the identity.
Assume $\rank(\mD) = R$ and therefore $\msigma = (\vs_1, \dots, \vs_R) \in \sR^{D \times R} = \smash{\sum_{r=1}^R \vs_r \vs_r^\top}$.
For example, $\mD$ represents the diffusion tensor in Kolmogorov-type PDEs like the Fokker-Planck equation \cite{hu2023hutchinson}, and $\msigma$ can depend on $\vx_0$ \cite{fa2011solution}.
The weighted Laplacian contains the weighted Hessian's trace $\Tr(\msigma \msigma^{\top} \partial^2 [\vf]_c)$for each output element $c$ of a function.
In the general case,
\begin{subequations}
  \begin{align}\label{eq:weighted-laplacian}
    \textstyle % Comment out this line if we have enough space
    \underbrace{
    \Delta_\mD \vf(\vx_0)
    }_{\in \sR^C}
    :=
    \left<
    \partial^2 \vf(\vx_0), \mD
    \right>
    \quad
    \begin{cases}
      = \sum_{r=1}^R
      \left< \partial^2 \vf(\vx_0), \vs_r^{\otimes 2} \right>
      & \text{(exact)}
      \\
      \overset{\text{\cite{hu2023hutchinson}}}{\approx}
      \frac{1}{S}
      \sum_{s=1}^S
      \left< \partial^2 \vf(\vx_0), (\msigma \vv_s)^{\otimes 2} \right>
      & \text{(stochastic)}
    \end{cases}
    .
  \end{align}
  Computing it requires computing the following 2-jets with standard Taylor mode:
  \begin{align}
    \begin{array}{rlrlrlll}
      \{(\vx_{0,r} & = \vx_0, &\vx_{1, r} & = \vs_r, & \vx_{2,r} &= \vzero)\}_{r=1}^R
                                                                   \quad
      &{\color{tab-orange} 1 + R + R\, \text{vectors}}
        \quad
      &\text{(exact)}
      \\[1ex]
      \{(\vx_{0,s} & = \vx_0, &\vx_{1, s} & = \msigma \vv_s, &\vx_{2,s} & = \vzero)\}_{s=1}^S
                                                                          \quad
      &{\color{tab-orange} 1 + S + S\, \text{vectors}}
        \quad
      &\text{(stochastic)}
    \end{array}.
  \end{align}
\end{subequations}
Collapsing standard Taylor mode yields {\color{tab-green}$1 + R + 1$} (exact) and {\color{tab-green}{$1 + S + 1$}} (stochastic) vectors.
This yields the modified forward Laplacian from \citet{li2024dof}; collapsing the stochastic variant speeds up the Hutchinson trace estimator from \citet{hu2023hutchinson}.
For indefinite $\mD$, we can simply apply this scheme to the positive and negative eigen-spaces.
However, such weighted Laplacians are not used in practise.

\subsection{Collapsed Taylor Mode for Arbitrary Mixed Partial Derivatives}
So far, we discussed operators that result from contracting the second-order derivative tensor with a coefficient matrix ($\mI$ or $\mD$) that can conveniently be written as sum of vector outer products.
For orders higher than two, the coefficient tensor can in general \emph{not} be decomposed as such.
To tackle this problem, we extend our framework to transform a differential operator containing mixed-partial derivatives into a family of jets using the result of \citet{griewank_evaluating_1999}.
We will then demonstrate the approach on the biharmonic operator with 4-dimensional coefficient tensor
\begin{align}
  \label{eq:biharm}
  \textstyle % Comment out this line if we have enough space
  \Delta^2 \vf(\vx_0)
  % \coloneqq
  % \Delta(\Delta \vf(\vx_0))
  \quad
  \begin{cases}
    =
    \sum_{d_1=1}^D \sum_{d_2=1}^D
    \left<
    \partial^4 \vf(\vx_0),
    \ve_{d_1}^{\otimes 2} \otimes \ve_{d_2}^{\otimes 2}
    \right>
    & \text{(exact)}
    \\
    \overset{\text{\cite{shi2024stochastic}}}{\approx}
    \frac{1}{S}
    \sum_{s=1}^S
    \left< \partial^4 \vf(\vx_0), \vv_s^{\otimes 4} \right>
    & \text{(stochastic)}
  \end{cases}
\end{align}
The stochastic version is easy. We simply draw $S$ standard normal vectors, then propagate the coefficients $(\vx_{0,s} = \vx_0, \vx_{1,s} = \vv_s, \vx_{2,s} = \vx_{3,s} = \vx_{4,s} = \vzero)$.
Using standard Taylor mode, this uses ${\color{tab-orange} 1 + S + S + S + S}$ vectors.
Collapsing Taylor mode uses ${\color{tab-green} 1 + S + S + S + 1}$ vectors.
For the exact biharmonic, we need to develop an approach to compute mixed partials.

\paragraph{General approach.}
Assume we want to contract the $K$-th order derivative tensor $\partial^K \vf(\vx_0)$ with a coefficient tensor $\tC \in (\sR^D)^{\otimes K}$.
We can always express this tensor in a tensor product basis,
\begin{align}\label{eq:sums-k-directional}
  \textstyle % Comment out this line if we have enough space
  \left<
  \partial^K \vf(\vx_0), \tC
  \right>
  =
  \sum_{d_1=1}^{D_1} \dots \sum_{d_P=1}^{D_P}\left<
  \partial^{K} \vf(\vx_0),
  \vv_{d_1}^{\otimes p_1}
  \otimes \ldots \otimes
  \vv_{d_P}^{\otimes p_P}
  \right>
  \,
  \in \sR^C\,,
\end{align}
where the $p_i$s sum to $K$ and the $D_i$s are at most $D$ (in the worst case $(D_i, p_i) = (D, 1)\, \forall i$).
For the biharmonic \cref{eq:biharm}, we identify $K = 4, P = 2, \vp = (2, 2), D_1 = D_2 = D, \vv_{d_1} = \ve_{d_1}$, and $\vv_{d_2} = \ve_{d_2}$.
From the Fa\'a di Bruno formula, we know that we can only compute terms of the form $\langle \partial^{K} \vf(\vx_0), \vv^{\otimes K}\rangle$ with a $K$-jet.
The challenge in \cref{eq:sums-k-directional} is that it includes terms whose directions do \emph{not} coincide in all directions (\eg for the biharmonic we have $P=2$ different directions).

Fortunately, \citet{griewank_evaluating_1999} derived an approach to reconstruct such mixed-direction terms by linear combination of a \emph{family} of $K$-jets.
This family is determined by all vectors $\vq \in \sN^P$ whose entries, like $\vp$ from above, sum to $K$ (see \cref{fig:ttc_biharm_coeffs} for an illustration for the biharmonic (5 directions)).
The $K$-jets along these directions are then combined with coefficients $\gamma_{\vp, \vq} \in \sR$, whose definition we provide in \cref{sec:appendix_ttc}.
In summary, we get
\begin{equation}
  \label{eq:ttc_general}
  \textstyle % Comment out this line if we have enough space
  \!\!\!\!\!
  \left<
    \partial^{K} \vf(\vx_0),
    \vv_{d_1}^{\otimes p_1}
    \otimes \ldots \otimes
    \vv_{d_P}^{\otimes p_P}
  \right>
  = \sum_{\vq \in \sN^P, \lVert \vq \rVert_1 = K}
  \frac{\gamma_{\vp, \vq}}{K!}
  \left<
    \partial^{K}\vf(\vx_0),
    \left(\sum_{p=1}^P \vv_{d_p} [\vq]_p\right)^{\otimes K}
  \right>\,.
\end{equation}
This construction allows us to rewrite \cref{eq:sums-k-directional} as
\begin{align*}
  \textstyle % Comment out this line if we have enough space
  \sum_{d_1=1}^{D_1} \dots \sum_{d_P=1}^{D_P}
  \sum_{\vq \in \mathbb{N}^P, \lVert \vq \rVert_1 = K}
  \frac{\gamma_{\vp, \vq}}{K!}
  \left<
  \partial^{K}\vf(\vx_0),
  \left(
  \sum_{p = 1}^P \vv_{d_p} [\vq]_p
  \right)^{\otimes K}
  \right>\,,
\end{align*}
and---since the coefficients $\gamma_{\vp\vq}$ only depend on the problem structure ($K$, $P$ and $\vp$) and \emph{not} on the function $\vf$ and the directions $\vv_{d_p}$ \cite{griewank_evaluating_1999}---we can pull out the inner sum to obtain the final expression
\begin{equation}\label{eq:ttc-general}
  \textstyle % Comment out this line if we have enough space
  \sum_{\vq \in \mathbb{N}^P, \lVert \vq \rVert_1 = K}
  \frac{\gamma_{\vp, \vq}}{K!}
  {\color{tab-green}
  \sum_{d_1=1}^{D_1} \dots \sum_{d_P=1}^{D_P}
  }
  {\color{tab-orange}
  \left<
    \partial^{K}\vf(\vx_0),
    \left(
      \sum_{p = 1}^P \vv_{d_p} [\vq]_p
    \right)^{\otimes K}
  \right>}\,.
\end{equation}
We can use standard Taylor mode to compute each \textcolor{tab-orange}{summand}, propagating different $K$-jets with coefficients $(\vx_0, \vx_1 = \sum_p \vv_{d_p}[\vq]_p, \vx_2 = \dots =\vx_K = \vzero)$, then \textcolor{tab-green}{collapse} the sum from the basis expansion.
Repeating this process for each $\vq$, then forming the linear combination using the $\gamma_{{\vp, \vq}}$s, yields the differential operator we sought to compute originally.
Further, we can often exploit symmetries in the $\gamma_{\vp\vq}$s and the basis vectors to further reduce the number of $K$-jets.
Please see \cref{sec:appendix_ttc} for a fully-contained example.

\begin{wrapfigure}[20]{r}{0.4\textwidth}
  \centering
  \vspace{-2ex}
  \input{figures/ttc_bilaplacian}
  \vspace{-2ex}
  \caption{\textbf{Illustration of \Cref{eq:ttc-general} for the Bi-Laplacian}, \ie, the jet directions and coefficients for computing the partial derivative $\nicefrac{\partial^4}{\partial^2 x_i \partial^2 x_j}$.
    They correspond to the border of a parallelepiped.}
  \label{fig:ttc_biharm_coeffs}
\end{wrapfigure}

\paragraph{Applied to the biharmonic operator.}
Let us now illustrate the most important aspects of applying \cref{eq:ttc-general} to the biharmonic \cref{eq:biharm}.
The full procedure is shown in \cref{eq:ttc_for_biharm}.
\Cref{fig:ttc_biharm_coeffs} illustrates the five vectors $\vq$ describing the family of $4$-jets we need to evaluate to isolate a mixed derivative $\langle \partial^4 \vf(\vx_0), \ve_i^{\otimes 2} \otimes \ve_j^{\otimes 2} \rangle$, and the coefficients $\gamma_{\vp, \vq}$.
A close look into the definition \cref{eq:ttc_coeff} shows the equality of the coefficients for $\vq = (4,0)$ with $\vq = (0, 4)$ and $\vq = (3, 1)$ with $\vq = (1, 3)$.
Exploiting those symmetries allows to reduce the family from five to three members to isolate one summand of the biharmonic (\cref{eq:ttc_for_biharm_2}), totalling $5D^2$ $4$-jets.
Using the symmetries in the $\gamma$s and the basis reduces this to $3 D^2$ (\cref{eq:ttc_for_biharm3}).
Removing doubly-computed terms brings down the number of $4$-jets to the final value $D + D(D-1) + \nicefrac{D(D-1)}{2}$.
All jets are computed in parallel.
In total, we need to propagate ${\color{tab-orange} TODO}$ \todo{Felix@Tim: please fill in if you have time} vectors using standard Taylor mode.
After collapsing, we propagate ${\color{tab-green}1 + 3D + 1 + 1 + 3 D(D-1) + 1 + 1 + 3 \frac{D(D-1)}{2} + 1 = 9\frac{D^2}{2} - 3\frac{D}{2} + 6}$ vectors.

\paragraph{Summary \& limitations.}
\todo{Felix: Did not work on this paragraph. I think it might be better to mention it in the experiments because otherwise we end really week here and we don't have experiments/evidence to show that all the complicated math we introduced was still worth it.}
The above procedure describes a generic approach for computing linear differential operators with our collapsed Taylor mode.
% that can be combined with our proposed collapsing method.
% We demonstrated it on the Biharmonic Operator, as it is a commonly used operator of degree greater than two.
We also considered other proposed approaches, which underperform our contribution.
For a comparison, see \cref{sec:appendix_ttc_other_methods}.
Because of its special structure, there is another efficient scheme for computing the Biharmonic Operator that nests twice the Laplacian.
In the appendix, we briefly discuss this approach in combination with our collapsed Taylor mode.
However, our focus here was to show that our idea applies to other differential operators, therefore making it a relevant contribution.

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
