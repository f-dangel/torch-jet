We start with a self-contained introduction of Taylor-mode automatic differentiation~\citep[][Chapter 13]{griewank2008evaluating}.

\paragraph{Taylor mode automatic differentiation (scalar case).}
For simplicity, consider a scalar-valued function $f: \sR \to \sR, x \mapsto f(x)$, and a path $x(t): [-\tau, \tau] \to \sR$.
We will later introduce notation to seamlessly handle tensor-valued functions.
Assume we Taylor-expand the path in input space up to order $K$, i.e.\,$x(t) \approx \sum_{k=0}^K\nicefrac{t^k}{k!}
\left.\nicefrac{\partial^k x(t)}{\partial t^k}\right|_{t=0} \coloneqq \sum_{k=0}^K \nicefrac{t^k}{k!}
x_k$ with $x_k \coloneqq \left.\nicefrac{\partial^k f(x)}{\partial t^k}\right|_{t=0}$. This operation of creating a truncated Taylor approximation is called a \emph{$K$-jet}.
Our goal is to compute the $K$-jet of $f(x(t))$, given the $K$-jet of $x(t)$.
In notation, we want to compute $f_k \coloneqq \left.\nicefrac{\partial f(x(t))}{\partial t^k}\right|_{t=0}$ so that $f(x(t)) \approx \sum_{k=0}^K \nicefrac{t^k}{k!} f_k$:
\begin{center}
  \begin{tikzpicture}
    \node[align=center] (topleft) {Path in input space \\
      $x(t)$, $t \in [-\tau, \tau]$};

    \node[align=center, right=4cm of topleft] (topright) {Path in output space \\ $f(x(t))$};
    \draw [-Latex] (topleft.east) to node [midway, above] {$f$} (topright.west);

    \node[align=center, below=1cm of topright] (bottomright) {Truncated Taylor series
      \\
      $f(x(t)) \approx \sum_{k=0}^K \frac{t^k}{k!} f_k$
      \\
      {\color{maincolor}$(f_0, \dots, f_K)$}
    };
    \draw [-Latex] (topright.south) to node [midway, right] {$K$-jet} (bottomright.north);

    \node[align=center, below=1cm of topleft] (bottomleft) {Truncated Taylor series
      \\
      $x(t) \approx \sum_{k=0}^K \frac{t^k}{k!} x_k$
      \\
      {\color{maincolor} $(x_0, \dots, x_K)$}};
    \draw [-Latex] (topleft.south) to node [midway, left] {$K$-jet} (bottomleft.north);

    \draw [-Latex, maincolor] (bottomleft.east) to node [midway, above, maincolor] {Taylor mode} (bottomright.west);
  \end{tikzpicture}
\end{center}

Let's start by writing out the first two derivatives, for which we need the chain and product rules (for notational convenience, we omit the derivative evaluations at $t=0$):
\begin{subequations}
  \begin{align}
    f_0
    &=
      f(x_0)
    \\
    f_1
    &=
      \frac{\partial f}{\partial x} \frac{\partial x}{\partial t}
      =
      \frac{\partial f}{\partial x} x_1
    \\
    f_2
    &=
      \frac{\partial^2 f}{\partial x^2} \left( \frac{\partial x}{\partial t} \right)^2
      +
      \frac{\partial f}{\partial x} \frac{\partial^2 x}{\partial t^2}
      =
      \frac{\partial^2 f}{\partial x^2} x_1^2
      +
      \frac{\partial f}{\partial x} x_2
    \\
    f_3
    &=
      \frac{\partial^3 f}{\partial x^3} \left( \frac{\partial x}{\partial t} \right)^3
      +
      3 \frac{\partial f^2}{\partial x^2} \frac{\partial x}{\partial t}
      \frac{\partial^2 x}{\partial t^2}
      +
      \frac{\partial f}{\partial x} \frac{\partial^3 x}{\partial t^3}
      =
      \frac{\partial^3 f}{\partial x^3} x_1^3
      +
      3 \frac{\partial^2 f}{\partial x^2} x_1 x_2
      +
      \frac{\partial f}{\partial x} \frac{\partial^3 x}{\partial t^3}
      \intertext{At this point, we can start to see a pattern.
      The incoming Taylor coefficients $\{x_k\}$ are processed into the outgoing Taylor coefficients $\{f_k\}$ using derivatives of $f$.
      And the coefficient $f_k$ use only incoming derivatives up to that order, $\{x_{k'<k}\}$.
      The number of terms grows with $k$, and we can see that the incoming Taylor coefficients are chosen from the \emph{integer partitioning of $k$}, for instance $\partitioning(3) = \{ \{1,1,1\}, \{1, 2\}, \{3\} \}$.
      Finally, there is a also a multiplicity term that depends on the set of from the integer partitioning.
      In total, this gives the well-known Fa\`a die Bruno formula~\cite{arbogast1800calcul,hardy2006combinatorics,faa1857note}
      }
      \label{eq:faa-di-bruno}
      f_k
      &=
      \sum_{\sigma \in \partitioning(k)}
      \nu(\sigma) \frac{\partial^{|\sigma|} f}{\partial x^{|\sigma|}}
        \prod_{s \in \sigma} x_s
        \quad
        \text{with multiplicity}
        \quad
        \nu(\sigma)
        =
        \frac{k!}{
        \left(\prod_{s \in \sigma} n_s!\right)
        \left(\prod_{s \in \sigma} s!\right)
        }
  \end{align}
\end{subequations}
where $n_s$ counts the occurrences of $s$ in an integer partitioning $\sigma$, for instance $n_1(\{1,1,3\}) = 2$.

\paragraph{The vector/matrix/tensor-valued case.}
So far, we assumed a scalar-to-scalar function.
The generalization of \cref{eq:faa-di-bruno}

\paragraph{Function composition.}



\subsection{Computing Laplacians}
Taylor mode from the previous sub-section serves as backbone for computing many differential operators like the Laplacian.
The fundamental problem is to figure out how to set the jet degrees $K$, $x_k$ and $K$

\subsection{Using Linearity---Recovering the Forward Laplacian}

\paragraph{Handling $\sum_{i,j} c_{i,j} \nicefrac{\partial^2f}{\partial \evx_i \evx_j}$.} TODO

\subsection{Using Linearity in Randomization Taylor Mode}
\cite{shi2024stochastic}
%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
