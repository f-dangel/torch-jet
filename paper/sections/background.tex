Taylor-mode AD (or, simply, Taylor-mode) computes higher-order derivatives---as needed, \eg, for PDE operators---through propagation of Taylor coefficients according to the chain rule.

\input{figures/taylor_signature}

\paragraph{Scalar case.}
To illustrate Taylor-mode, consider the scalar function $f: \sR \to \sR$ and extend the input variable $x$ to a path $x(t)$ whose form is a uni-variate Taylor polynomial of degree $K$, $\smash{x(t) = \sum_{k=0}^K \frac{t^k}{k!} x_k}$ with $x_k$ the $k$-th Taylor coefficient.
If $f$ is smooth enough, we can evaluate Taylor coefficients of the transformed path $\smash{f(x(t)) = \sum_{k=0}^K \frac{t^k}{k!} f_k}$ with $\smash{f_k \coloneqq \frac{\mathrm{d}^k}{\mathrm{d}t^k} f(x(t)) |_{t=0}}$.
The chain rule provides the coefficients' propagation rules.
\Eg, for degree $K=3$ we get
\begin{align}
  \label{eq:taylor-mode-scalar}
  \begin{matrix*}[l]
    f_0 = f(x_0)\,,
    \\[0.75ex]
    f_1 = \partial f(x_0) x_1\,,
  \end{matrix*}
  \qquad
  \begin{matrix*}[l]
    f_2 = \partial^2 f(x_0)x_1^2 + \partial f(x_0) x_2\,,
    \\[0.75ex]
    f_3
    = \partial^3 f(x_0)x_1^3 + 3 \partial^2 f(x_0) x_1 x_2 + \partial f(x_0) x_3\,.
  \end{matrix*}
\end{align}
\citet{faa1857note} provided the general formula for $f_k$, and \citet{fraenkel1978formulae} extended it to the multivariate case \cite[see also][]{arbogast1800calcul,hardy2006combinatorics}.
It serves as foundation for Taylor-mode to compute higher-order derivatives \citep[\eg][\S13]{griewank2008evaluating}:
setting $x_1 = 1, x_2 = x_3 = 0$ yields $f_1 = \partial f(x_0), f_2 = \partial^2 f(x_0), f_3 = \partial^3 f(x_0)$.
We call the uni-variate Taylor polynomial of a function $x(t)$ of degree $K$, represented by the coefficients $(x_0, \dots, x_K)$, the \emph{$K$-jet of $x$}, following the terminology of JAX's Taylor-mode.

\paragraph{Notation for multi-variate case.}
We consider the general case of computing higher-order derivatives, \eg PDE operators, of a vector-to-vector function $\vf: \sR^D \to \sR^C$.
This requires additional notation to generalize \cref{eq:taylor-mode-scalar}.
Given $K$ vectors $\vv_1, \dots, \vv_K \in \sR^D$, we write their tensor product as
\begin{equation*}
  \otimes_{k=1}^K \vv_k = \vv_1 \otimes \ldots \otimes \vv_K
  \in ( \sR^D )^{\otimes K}
  \quad
  \text{with entries}
  \quad
  \left[\otimes_{k=1}^K \vv_k\right]_{d_1, \dots, d_K}
  = [\vv_1]_{d_1} \cdots [\vv_K]_{d_K}
\end{equation*}
for $d_1, \dots, d_K \in \{1, \dots, D\}$, and compactly write $\vv^{\otimes K} = \otimes_{k=1}^K \vv$.
We define the inner product of two tensors $\smash{\tA, \tB \in (\sR^{D})^{\otimes K}}$ as the Euclidean inner product of their flattened versions
\begin{align}\label{eq:derivative-tensor-scalar-product}
  \textstyle % Comment out this line if we have enough space
  \left\langle
  \tA, \tB
  \right\rangle
  \coloneqq
  \sum_{d_1}
  \sum_{d_2}
  \dots
  \sum_{d_K}
  \tA_{d_1, d_2, \dots, d_K}
  \tB_{d_1, d_2, \dots, d_K} \in \sR\,.
\end{align}
We allow broadcasting in \Cref{eq:derivative-tensor-scalar-product}: if one tensor has more dimensions but matching trailing dimensions, we take the inner product for each component of the leading dimensions.
This allows to express contractions with derivative tensors of vector-valued functions, \eg
contracting the $k$-th derivative tensor $\partial^k \vf(\vx_0) \in \sR^C \otimes (\sR^D)^k$, such that $\langle \tA, \partial^k \vf(\vx_0) \rangle \in \sR^C$.

\paragraph{Multi-variate case \& composition.}
Evaluating the $K$-jet of $\vf$ at an argument $\vx_0 \in \sR^D$ starts with the extension of $\vx_0$ to a smooth path $\vx: \sR \to \sR^D$ with $\vx(0) = \vx_0$.
The $K$-jet of $\vf$ is defined as \todo{Felix@Tim: Wouldn't it be better to define the $K$-jet as mapping from $\times_{k=0}^K \sR^D \to \times_{k=0}^K \sR^C$ ?
  This would be more aligned with the propagation in \cref{eq:taylor-mode-composition}.}
\begin{align*}
  \textstyle % Comment out this line if we have enough space
  J^K \vf : \sR \to \sR^C\,,
  \quad (J^K \vf)(t) := \sum_{k=0}^K \frac{t^k}{k!} \vf_k
  \quad \text{with} \quad
  \vf_k := \left. \frac{\mathrm{d}^k}{\mathrm{d}t^k} \vf(\vx(t)) \right|_{t=0}
\end{align*}
and requires the $K$-jet of $\vx$, $(J^K \vx)(t) := \sum_{k=0}^K \frac{t^k}{k!} \vx_k$ (illustrated in \cref{fig:utp}).

As is common for AD, the computation of the $\vf_k$ known as Taylor-mode AD relies on composing $\vf$ of elemental functions with known derivatives, and the chain rule.
In the simplest case, let $\vf$ be composed of two elemental functions $\vg$ and $\vh$, $\vf = \vg \circ \vh: \sR^D \to \sR^I \to \sR^C$ with intermediate dimension $I$.
Given $J^K\vx$, Taylor-mode calculates the $K$-jet of $\vf$ by successively evaluating all $\vf_k$ through the chain rule (Fa√† di Bruno's formula \eqref{eq:faa-di-bruno}, generalized to multiple dimensions), \todo{Felix: I find this explanation confusing because it does not explain how decomposition is used.
  Shouldn't we say that we first push the $K$-jet through $h$, then through $g$, and this gives the $K$-jet of $f$?}
\begin{align}
  \label{eq:faa-di-bruno}
  % \textstyle % Comment out this line if we have enough space
  \vf_k = \vg_k
  =
  \sum_{\sigma \in \partitioning(k)}
  \nu(\sigma)
  \left<
  \partial^{|\sigma|} \vg,
  \tensorprod{s \in \sigma} \vh_s
  \right>
  \quad
  \text{with}
  \quad
  \nu(\sigma)
  =
  \frac{k!}{
    \left(
      \prod_{s \in \sigma
      }
      n_s!
    \right)
    \left(
      \prod_{s \in \sigma}
      s!
    \right)
  }\,.
\end{align}
Here, $\partitioning(k)$ is the integer partitioning of $k$ (a set of sets), $\nu$ is a multiplicity function, and $n_s$ counts occurrences of $s$ in an integer partitioning $\sigma$ (\eg $n_1(\{1,1,3\}) = 2$ and $n_3 = 1$).
\citet[][\S13]{griewank2008evaluating} presents explicit formulas of common elemental functions that have quadratic complexity in $K$.
In summary, this yields the propagation scheme (where $\vx_k \in \sR^D$, $\vh_k \in \sR^I$, $\vf_k \in \sR^C$)
\begin{align}\label{eq:taylor-mode-composition}
  \begin{split}
    &\begin{pmatrix*}
      \vx_0
      \\
      \vx_1
      \\
      \vx_2
      \\
      \vdots
      \\
      \vx_K
    \end{pmatrix*}
      \!\overset{\text{(\ref{eq:faa-di-bruno})}}{\to}\!
      \begin{pmatrix*}[l]
        \vh_0 \!=\!  \vh(\vx_0)
        \\
        \vh_1 \!=\!  \left<
        \partial \vh(\vx_0),
        \vx_1
        \right>
        \\
        \vh_2 \!=\! \left<
        \partial^2 \vh(\vx_0),
        \vx_1 \otimes \vx_1
        \right>
        \!+\!
        \left <
        \partial \vh(\vx_0),
        \vx_2
        \right>
        \\
        \vdots
        \\
        \vh_K \!=\!
        \displaystyle \sum_{
        \mathclap{
        \sigma \in \partitioning(K)
        }
        }
        \nu(\sigma) \left<
        \partial^{|\sigma|} \vh(\vx_0),
        \tensorprod{s \in \sigma} \vx_s
        \right>\!\!\!
      \end{pmatrix*}
    \\
    &\!\!\overset{\text{(\ref{eq:faa-di-bruno})}}{\to}\!
      \left(\!\!\!
      \begin{array}{l}
        \vg_0 \!=\!  \vg(\vh_0)
        \\
        \vg_1 \!=\! \left<
        \partial \vg(\vh_0),
        \vh_1
        \right>
        \\
        \vg_2 \!=\! \left<
        \partial^2 \vg(\vh_0),
        \vh_1 \!\otimes\! \vh_1\right>
        \!+\!
        \left< \partial \vg(\vh_0),
        \vh_2
        \right>
        \\
        \vdots
        \\
        \vg_K \!=\!
        \displaystyle\sum_{
        \mathclap{
        \sigma \in \partitioning(K)
        }
        }
        \nu(\sigma) \left<
        \partial^{|\sigma|} \vg(\vh_0),
        \tensorprod{s \in \sigma} \vh_s
        \right>
      \end{array}
      \!\!\!\!
      \right)
      \!\!=\!\!
      \left(\!\!\!
      \begin{array}{l}
        \vf_0 \!=\!  \vf(\vx_0)
        \\
        \vf_1 \!=\! \left<
        \partial \vf(\vx_0),
        \vx_1
        \right>
        \\
        \vf_2 \!=\! \left<
        \partial^2 \vf(\vx_0),
        \vx_1 \!\otimes\! \vx_1
        \right>
        \!+\!
        \left< \partial \vf(\vx_0),
        \vx_2
        \right>
        \\
        \vdots
        \\
        \vf_K \!=\!
        \displaystyle\sum_{
        \mathclap{
        \sigma \in \partitioning(K)
        }
        }
        \nu(\sigma) \left<
        \partial^{|\sigma|} \vf(\vx_0),
        \tensorprod{s \in \sigma} \vx_s
        \right>
      \end{array}
      \!\!\!\!
      \right)
  \end{split}
\end{align}
which describes the forward propagation of a single $K$-jet.
In practise, however, computing PDE operators requires evaluating \emph{multiple} $K$-jets in parallel, and accumulating their results.
We show how to pull this accumulation inside Taylor mode's propagation scheme, thereby collapsing it.

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
